\title{CS 383 - Machine Learning}
\author{
        Assignment 1 - Dimensionality Reduction\\
        Winter 2017
}
\date{}
\documentclass[12pt]{article}
\usepackage[margin=0.7in]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}


\begin{document}
\maketitle


\section*{Introduction}
In this assignment you'll work on visualizing data and reducing its dimensionality.\\

\noindent
You may not use any function from the Matlab ML library in your code.  Look at the \emph{Matlab Functions} section on Blackboard for a list of functions that are ok to use.\\

\noindent
In particular for this assignment you \textbf{MAY NOT} use Matlab functions like:
\begin{itemize}
\item pca
\item entropy
\end{itemize}

\noindent
But you \textbf{MAY} use basic statistical functions like:
\begin{itemize}
\item std
\item mean
\item cov
\item eig
\end{itemize}

\begin{center}
\emph{As a reminder, make sure to clear out old variables prior to running your script}.
\end{center}


\section*{Grading}
\begin{table}[h]
\begin{centering}
\begin{tabular}{|l|l|}
\hline
Part 1 (Theory) & 23pts \\
Part 2 (PCA) & 30pts\\
Report & 5pts\\
\hline
\textbf{TOTAL} & 58pts\\
\hline
\end{tabular}
\caption{Grading Rubric}
\end{centering}
\end{table}

\newpage
\section*{DataSets}
\paragraph{Pima Indians Diabetes Data Set} 
In this dataset of 768 instances of testing Pima Indians for diabetes each row has the following information
\begin{enumerate}
\item Class Label (-1=negative,+1=positive)
\item Number of times pregnant
\item Plasma glucose concentration
\item Diastolic blood pressure (mm Hg)
\item Triceps skin fold thinkness (mm)
\item Insulin (mu U/ml)
\item Body mass index ($kg/m^2$)
\item Diabetes pedigree function
\item Age (yrs)
\end{enumerate}
Data obtained from:  https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes

\newpage
\section{Theory Questions}
\begin{enumerate}

\item Consider the following data:\\
\begin{center}
$
 \begin{bmatrix}
	-2 & 1\\
	-5 & -4\\	
	-3 & 1\\
	0 & 3\\
	-8 & 11\\
	-2 & 5\\
	1 & 0\\
	5 & -1\\
	-1 & -3\\
	6 & 1\\
\end{bmatrix}
$
\end{center}
	\begin{enumerate}
	\item Find the principle components of the data (you must show the math, including how you compute the eivenvectors and eigenvalues).  Make sure you standardize the data first and that your principle components are normalized to be unit length.  As for the amount of detail needed in your work imagine that you were working on paper with a basic calculator.  Show me whatever you would be writing on that paper.  (5pts).
	\item Project the data onto the principal component corresponding to the largest eigenvalue found in the previous part (3pts).
	\end{enumerate}

\item Consider the following data:\\
\begin{center}
Class 1 = 
$
 \begin{bmatrix}
	-2 & 1\\
	-5 & -4\\	
	-3 & 1\\
	0 & 3\\
	-8 & 11\\
	
\end{bmatrix}
$
, Class 2 = 
$
 \begin{bmatrix}
	-2 & 5\\
	1 & 0\\
	5 & -1\\
	-1 & -3\\
	6 & 1\\
\end{bmatrix}
$
\end{center}
	\begin{enumerate}
	\item Compute the information gain for each feature.  You could standardize the data overall, although it won't make a difference. (5pts).
	\item Which feature is more discriminating based on results in part a (1pt)?
	\item Using LDA, find the direction of projection (you must show the math, however for this one you don't have to show the computation for finding the eigenvalues and eigenvectors).  Normalize this vector to be unit length (5pts).
	\item Project the data onto the principal component found in the previous part (3pts).
	\item Does the projection you performed in the previous part seem to provide good class separation?  Why or why not (1pt)?
	\end{enumerate}
\end{enumerate}


\newpage
\section{Dimensionality Reduction via PCA}\label{pca}
Download the dataset \emph{diabetes.csv} from Blackboard.  This dataset has eight features ($D=8$) and 768 samples ($N=78$).  The first column is the class label \{-1, 1\}.  \textbf{However} your script should be able to work on any dataset that lacks a header row and then has an arbitrary number of data observations, $N$, one per row, in the format:
\begin{center}
$(y_i, x_{i,1}, x_{i,2}, ..., x_{i,D})$
\end{center}
where $x_{i,j}$ are real valued numbers, $r_i\in\{-1, 1\}$, and $D$ is the number of features.\\

\noindent
\paragraph{Write a script that:}
\begin{enumerate}
  \item Reads in the data
  \item Standardizes the data (except for the first column of course)
  \item Reduces data (except for the first column of course) to 2D using PCA
  \item Graphs the data for visualization
      \begin{enumerate}
        \item   Even though we're not using class labels to do the dimensionality reduction, plot the -1 data in blue and the +1 data in red
      \end{enumerate}
\end{enumerate}


Your graph should end up looking similar to Figure \ref{PCA}.
\begin{figure}[H]
\begin{center}
\includegraphics{Part1.png}
\caption{2D PCA Projection of data}
\label{PCA}
\end{center}
\end{figure}


\newpage
\section*{Submission}
For your submission, upload to Blackboard a single zip file containing:

\begin{enumerate}
\item PDF Writeup
\item Source Code
\item readme.txt file
\end{enumerate}

\noindent
The readme.txt file should contain information on how to run your code to reproduce results for each part of the assignment.\\

\noindent
The PDF document should contain the following:
\begin{enumerate}
\item Part 1: Your answers to the theory questions.
\item Part 2: The visualization of the PCA result
\end{enumerate}

\end{document}

